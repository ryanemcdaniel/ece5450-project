{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yp5Nn7lzV3J6"
      },
      "source": [
        "# Load all imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sZzTc_qcr0ge"
      },
      "outputs": [],
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import task3 as helper\r\n",
        "import net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Globals, CNNs, and Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "oriPATH = 'C:/Users/Ryan/Desktop/machine-learning/part2/cnn'\r\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\r\n",
        "learningRates = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\r\n",
        "numEpochs = 50\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)\r\n",
        "\r\n",
        "regNet = net.ReluNet()\r\n",
        "earlyNet = net.ReluNet()\r\n",
        "regNet = regNet.to(device)\r\n",
        "earlyNet = earlyNet.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m77sHXmJWHfx"
      },
      "source": [
        "# MNIST training and validation set augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JNDByYIhr4TU"
      },
      "outputs": [],
      "source": [
        "valid_ratio = 0.3\r\n",
        "\r\n",
        "noTransform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "])\r\n",
        "\r\n",
        "transform = transforms.Compose([\r\n",
        "    # define your data augmentation here!\r\n",
        "    transforms.RandomRotation(degrees=60),\r\n",
        "    transforms.RandomRotation(degrees=300),\r\n",
        "    transforms.RandomRotation(degrees=30),\r\n",
        "    transforms.RandomRotation(degrees=330),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "])\r\n",
        "\r\n",
        "nb_train = int((1.0 - valid_ratio) * len(train_valid_dataset))\r\n",
        "nb_valid =  int(valid_ratio * len(train_valid_dataset))\r\n",
        "\r\n",
        "notTransformed = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=noTransform)\r\n",
        "transformed = = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\r\n",
        "\r\n",
        "train_dataset, valid_dataset = torch.utils.data.dataset.random_split(notTransformed, [nb_train, nb_valid])\r\n",
        "nt_trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "nt_validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=1000, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "\r\n",
        "t_train_dataset, t_valid_dataset = torch.utils.data.dataset.random_split(transformed, [nb_train, nb_valid])\r\n",
        "t_trainloader = torch.utils.data.DataLoader(t_train_dataset, batch_size=1000, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "t_validloader = torch.utils.data.DataLoader(t_valid_dataset, batch_size=1000, shuffle=True, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "slDGVTtkXd-Z"
      },
      "source": [
        "# Define the loss function and the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ml4xvTi7sgCE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "regOpt = optim.Adam(regNet.parameters(), lr=0.001)\r\n",
        "earlyOpt = optim.Adam(earlyNet.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8dLwz9XsYkNJ"
      },
      "source": [
        "# Train the CNN and store the best model based on the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "colab_type": "code",
        "id": "csCvcF7Ss1Ud",
        "outputId": "7e62b4de-04c9-4cb8-d70b-aaeb5071f410"
      },
      "outputs": [],
      "source": [
        "import time\r\n",
        "import os as OO\r\n",
        "OO.mkdir(oriPATH + '/task3')\r\n",
        "PATH = oriPATH + '/task3'\r\n",
        "\r\n",
        "regTrainingLoss = []\r\n",
        "regValidationLoss = []\r\n",
        "earlyTrainingLoss = []\r\n",
        "earlyValidationLoss = []\r\n",
        "\r\n",
        "train, val = helper.runCNN(trainloader, device, regOpt, regNet, criterion, validloader, PATH, 'regNet', numEpochs)\r\n",
        "earlyTrainingLoss.append(train)\r\n",
        "earlyValidationLoss.append(val)\r\n",
        "train, val = helper.runCNN_earlyStop(trainloader, device, earlyOpt, earlyNet, criterion, validloader, PATH, 'earlyNet', numEpochs)\r\n",
        "regTrainingLoss.append(train)\r\n",
        "regValidationLoss.append(val)\r\n",
        "\r\n",
        "np.save(OO.path.join(PATH, 'regTrainingLoss.npy'), regTrainingLoss)\r\n",
        "np.save(OO.path.join(PATH, 'regValidationLoss.npy'), regValidationLoss)\r\n",
        "np.save(OO.path.join(PATH, 'earlyTrainingLoss.npy'), earlyTrainingLoss)\r\n",
        "np.save(OO.path.join(PATH, 'earlyValidationLoss.npy'), earlyValidationLoss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yfvPe-jSYsrR"
      },
      "source": [
        "# Define the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UQSOIHv7yf-3"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\r\n",
        "     transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "])\r\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3r7FPw9MZoMB"
      },
      "source": [
        "# Infer on the whole test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "F246Hc0QzLLV",
        "outputId": "95e3f967-1334-4738-edd6-535cccdf2486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 epochs for regular network: 98.710 % accuracy\n",
            "10 epochs for early stop network: 98.710 % accuracy\n"
          ]
        }
      ],
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=2, pin_memory=True)\r\n",
        "\r\n",
        "import os as OO\r\n",
        "PATH = oriPATH + '/task3'\r\n",
        "\r\n",
        "accuracy = []\r\n",
        "\r\n",
        "testNet = net.ReluNet()\r\n",
        "testNet = testNet.to(device)\r\n",
        "testNet.load_state_dict(torch.load(OO.path.join(PATH, 'regNet.pth')))\r\n",
        "correct, total = helper.testCNN(testloader, testNet, device)\r\n",
        "accuracy.append(100 * correct / total)\r\n",
        "testNet2 = net.ReluNet()\r\n",
        "testNet2 = testNet2.to(device)\r\n",
        "testNet2.load_state_dict(torch.load(OO.path.join(PATH, 'earlyNet.pth')))\r\n",
        "correct, total = helper.testCNN(testloader, testNet, device)\r\n",
        "accuracy.append(100 * correct / total)\r\n",
        "\r\n",
        "sTrain = np.load(OO.path.join(PATH, 'regTrainingLoss.npy'))\r\n",
        "rTrain = np.load(OO.path.join(PATH, 'earlyTrainingLoss.npy'))\r\n",
        "\r\n",
        "regNumEpochs = len(sTrain[0])\r\n",
        "earlyNumEpochs = len(rTrain[0])\r\n",
        "\r\n",
        "print(\"regular network: {} epochs %.3F %% accuracy\".format(regNumEpochs) % accuracy[0])\r\n",
        "print(\"early stop network: {} epochs %.3F %% accuracy\".format(earlyNumEpochs) % accuracy[1])\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graph Training Losses and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "epochs = range(0, 10)\r\n",
        "fig, ax = plt.subplots(1, 2)\r\n",
        "fig.set_size_inches(20, 10)\r\n",
        "\r\n",
        "ax[0].plot(epochs, sTrain[0], label='sigmoid')\r\n",
        "ax[0].plot(epochs, rTrain[0], label='relu')\r\n",
        "\r\n",
        "ax[1].plot(epochs, sigAccuracy, label='sigmoid')\r\n",
        "ax[1].plot(epochs, relAccuracy, label='relu')\r\n",
        "\r\n",
        "ax[0].legend(loc=\"lower left\")\r\n",
        "ax[1].legend(loc=\"upper left\")\r\n",
        "\r\n",
        "ax[0].set_title(\"Training Loss per Epoch\")\r\n",
        "ax[1].set_title(\"Accuracy per Epoch\")\r\n",
        "\r\n",
        "ax[0].set_xlabel(\"Epoch\")\r\n",
        "ax[0].set_ylabel(\"Training Loss\")\r\n",
        "ax[1].set_xlabel(\"Epoch\")\r\n",
        "ax[1].set_ylabel(\"Training Loss\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}