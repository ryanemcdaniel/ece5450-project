{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "startNet = ''\r\n",
        "saveNetAs = 'start'\r\n",
        "saveResultsAs = 'start.npy'\r\n",
        "loadNet = 'start'\r\n",
        "loadResult = 'start.npy'\r\n",
        "saveTestAs = 'test.npy'\r\n",
        "loadTest = 'test.npy'\r\n",
        "valid_ratio = 0.3\r\n",
        "batchSize = 512\r\n",
        "numEpochs = 1\r\n",
        "rangeEpochs = 10\r\n",
        "learningRates = [0.0001, 0.001, 0.01]\r\n",
        "\r\n",
        "import torch\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)\r\n",
        "\r\n",
        "import os\r\n",
        "oriPATH = 'C:/Users/Ryan/Desktop/machine-learning/part2/cnn'\r\n",
        "task = '/final'\r\n",
        "subFolder = '/round4'\r\n",
        "if not os.path.exists(oriPATH + task):\r\n",
        "    os.makedirs(oriPATH + task)\r\n",
        "PATH = oriPATH + task + subFolder\r\n",
        "if not os.path.exists(PATH):\r\n",
        "    os.makedirs(PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "        self.lossFunction = nn.CrossEntropyLoss()\r\n",
        "        self.act = nn.SELU()\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(3, 48, kernel_size=3, stride=1, padding=1)\r\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\r\n",
        "        # self.norm1 = nn.BatchNorm2d(96)\r\n",
        "        self.conv2 = nn.Conv2d(48, 96, kernel_size=3, stride=1, padding=1)\r\n",
        "        self.conv3 = nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=1)\r\n",
        "        # self.norm2 = nn.BatchNorm2d(192)\r\n",
        "        self.conv4 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1)\r\n",
        "        self.drop1 = nn.AlphaDropout(p=0.05)\r\n",
        "        # self.drop2 = nn.Dropout2d(0.05)\r\n",
        "        self.fc1 = nn.Linear(192 * 8 * 8, 512)\r\n",
        "        self.fc2 = nn.Linear(512, 256)\r\n",
        "        self.fc3 = nn.Linear(256, 128)\r\n",
        "        self.fc4 = nn.Linear(128, 10)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.pool(self.act(self.conv1(x)))\r\n",
        "        x = self.act(self.conv2(x))\r\n",
        "        # x = self.norm1(x)\r\n",
        "        x = self.pool(self.act(self.conv3(x)))\r\n",
        "        # x = self.norm2(x)\r\n",
        "        x = self.act(self.conv4(x))\r\n",
        "        x = x.view(-1, 192 * 8 * 8)\r\n",
        "        x = self.act(self.fc1(x))\r\n",
        "        x = self.act(self.fc2(x))\r\n",
        "        x = self.act(self.fc3(x))\r\n",
        "        x = self.fc4(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "    def procBatch(self, batch):\r\n",
        "        data, labels = batch\r\n",
        "        pred = self(data)\r\n",
        "        return self.lossFunction(pred, labels)\r\n",
        "    \r\n",
        "    def save(self, PATH, fileName, epoch):\r\n",
        "        torch.save(self.state_dict(), os.path.join(PATH, \"{}_epoch_{}.pth\".format(fileName, epoch)))\r\n",
        "\r\n",
        "    def load(self, PATH, fileName):\r\n",
        "        self.load_state_dict(torch.load(os.path.join(PATH, fileName)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10 Dataset and Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "dataTransform = transforms.Compose([\r\n",
        "    transforms.RandomOrder([\r\n",
        "        transforms.RandomCrop(32, padding=4),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomAffine((-90, 90)),\r\n",
        "        transforms.RandomResizedCrop(32)\r\n",
        "    ]),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    # Normalization numbers retrieved from https://github.com/kuangliu/pytorch-cifar/issues/19\r\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\r\n",
        "])\r\n",
        "\r\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=dataTransform)\r\n",
        "nb_train, nb_valid = int((1.0 - valid_ratio) * len(trainset)), int(valid_ratio * len(trainset))\r\n",
        "train_dataset, valid_dataset = torch.utils.data.dataset.random_split(trainset, [nb_train, nb_valid])\r\n",
        "\r\n",
        "trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "validLoader = torch.utils.data.DataLoader(valid_dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=True)\r\n",
        "\r\n",
        "testTransform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\r\n",
        "])\r\n",
        "\r\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=testTransform)\r\n",
        "testLoader = torch.utils.data.DataLoader(testset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8dLwz9XsYkNJ"
      },
      "source": [
        "# Train and Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "colab_type": "code",
        "id": "csCvcF7Ss1Ud",
        "outputId": "7e62b4de-04c9-4cb8-d70b-aaeb5071f410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6998442\n",
            "{'train': tensor(2.1248, device='cuda:0', grad_fn=<MeanBackward0>), 'valid': tensor(1.9738, device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# Training function\r\n",
        "def train(numEpochs, model, optimizer, train, valid):\r\n",
        "    bestEpoch = 0\r\n",
        "    best_loss = np.float('inf')\r\n",
        "    tally = []\r\n",
        "    for epoch in range(numEpochs):\r\n",
        "        runTrainLoss = []\r\n",
        "        for _, data in enumerate(train, 0):\r\n",
        "            optimizer.zero_grad()\r\n",
        "            trainLoss = model.procBatch((data[0].to(device), data[1].to(device)))\r\n",
        "            trainLoss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            runTrainLoss.append(trainLoss)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            runValidLoss = []\r\n",
        "            for _, data in enumerate(valid, 0):\r\n",
        "                runValidLoss.append(model.procBatch((data[0].to(device), data[1].to(device))))\r\n",
        "        \r\n",
        "        endTrain = torch.stack(runTrainLoss).mean()\r\n",
        "        endValid = torch.stack(runValidLoss).mean()\r\n",
        "        tally.append({'train': endTrain, 'valid': endValid})\r\n",
        "        model.save(PATH, saveNetAs, epoch)\r\n",
        "\r\n",
        "        valLoss = endValid.item()\r\n",
        "        if endValid < best_loss:\r\n",
        "            best_loss = endValid\r\n",
        "            bestEpoch = epoch\r\n",
        "\r\n",
        "        # stop early if it has been several epochs since last best\r\n",
        "        if (epoch - bestEpoch) > rangeEpochs:\r\n",
        "            break\r\n",
        "\r\n",
        "    return tally\r\n",
        "\r\n",
        "# Instantiate CNN and check params\r\n",
        "model = Net()\r\n",
        "if startNet != '':\r\n",
        "    model.load(PATH, startNet)\r\n",
        "model = model.to(device)\r\n",
        "print(sum([p.numel() for p in model.parameters()]))\r\n",
        "\r\n",
        "# Instantiate optimizer\r\n",
        "modelOpt = torch.optim.Adam(model.parameters(), lr=0.001)\r\n",
        "\r\n",
        "# Begin training\r\n",
        "result = train(numEpochs, model, modelOpt, trainLoader, validLoader)\r\n",
        "print(result[0])\r\n",
        "\r\n",
        "# Save for future reference\r\n",
        "import numpy as np\r\n",
        "np.save(os.path.join(PATH, saveResultsAs), result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}